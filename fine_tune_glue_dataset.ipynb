{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9056d36a",
   "metadata": {},
   "source": [
    "## code to fine tune deberta-v3-base modal on glue dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14355975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q transformers datasets evaluate accelerate\n",
    "\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "LR = 5e-5\n",
    "EPOCHS = 1\n",
    "WEIGHT_DECAY = 0.01\n",
    "OUTPUT_BASE = \"deberta-v3-glue\"\n",
    "\n",
    "TASK_TO_KEYS = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qqp\":  (\"question1\", \"question2\"),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"rte\":  (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "\n",
    "def make_training_args(**base_kwargs):\n",
    "    try:\n",
    "        return TrainingArguments(eval_strategy=\"epoch\", **base_kwargs)\n",
    "    except TypeError:\n",
    "        return TrainingArguments(evaluation_strategy=\"epoch\", **base_kwargs)\n",
    "\n",
    "def build_compute_metrics(task_name):\n",
    "    glue_metric = evaluate.load(\"glue\", task_name)\n",
    "    acc_metric = evaluate.load(\"accuracy\")  # always compute accuracy\n",
    "    is_reg = (task_name == \"stsb\")\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        preds, labels = eval_pred\n",
    "        if is_reg:\n",
    "            preds = preds.squeeze()\n",
    "            pearson_spearman = glue_metric.compute(predictions=preds, references=labels)\n",
    "            return {\n",
    "                \"pearson\": pearson_spearman[\"pearson\"],\n",
    "                \"spearmanr\": pearson_spearman[\"spearmanr\"],\n",
    "            }\n",
    "        else:\n",
    "            preds = preds.argmax(axis=-1)\n",
    "            glue_results = glue_metric.compute(predictions=preds, references=labels)\n",
    "            acc = acc_metric.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "            glue_results[\"accuracy\"] = acc\n",
    "            return glue_results\n",
    "    return compute_metrics\n",
    "\n",
    "def make_preprocess(tokenizer, s1, s2, is_reg):\n",
    "    def fn(batch):\n",
    "        if s2 is None:\n",
    "            enc = tokenizer(batch[s1], truncation=True, max_length=MAX_LENGTH)\n",
    "        else:\n",
    "            enc = tokenizer(batch[s1], batch[s2], truncation=True, max_length=MAX_LENGTH)\n",
    "        enc[\"labels\"] = [float(x) for x in batch[\"label\"]] if is_reg else batch[\"label\"]\n",
    "        return enc\n",
    "    return fn\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "for task, (s1, s2) in TASK_TO_KEYS.items():\n",
    "    print(f\"\\n================ GLUE Task: {task.upper()} ================\\n\")\n",
    "\n",
    "    ds = load_dataset(\"glue\", task)\n",
    "    is_reg = (task == \"stsb\")\n",
    "    num_labels = 1 if is_reg else len(ds[\"train\"].features[\"label\"].names)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "\n",
    "    preprocess = make_preprocess(tokenizer, s1, s2, is_reg)\n",
    "    encoded = ds.map(preprocess, batched=True, remove_columns=ds[\"train\"].column_names)\n",
    "\n",
    "    args = make_training_args(\n",
    "        output_dir=f\"{OUTPUT_BASE}-{task}\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=LR,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        logging_dir=f\"{OUTPUT_BASE}-{task}/logs\",\n",
    "        report_to=\"none\",\n",
    "        load_best_model_at_end=False,\n",
    "        logging_steps=50,\n",
    "    )\n",
    "\n",
    "    compute_metrics = build_compute_metrics(task)\n",
    "\n",
    "    if task == \"mnli\":\n",
    "        eval_main = encoded[\"validation_matched\"]\n",
    "        extra = [(\"validation_mismatched\", encoded[\"validation_mismatched\"])]\n",
    "    else:\n",
    "        eval_main = encoded[\"validation\"]\n",
    "        extra = []\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        #train_dataset=encoded[\"train\"],\n",
    "        #eval_dataset=eval_main,\n",
    "        train_dataset=encoded[\"train\"].shuffle(seed=42).select(range(1000)),\n",
    "        eval_dataset=eval_main.select(range(200)),\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    print(f\"\\n--- {task.upper()} | Eval on validation ---\")\n",
    "    print(trainer.evaluate(eval_dataset=eval_main))\n",
    "\n",
    "    for name, split in extra:\n",
    "        print(f\"\\n--- {task.upper()} | Eval on {name} ---\")\n",
    "        print(trainer.evaluate(eval_dataset=split))\n",
    "\n",
    "print(\"\\nâœ… Finished fine-tuning DeBERTa-v3-base on all 9 GLUE tasks (accuracy included).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
